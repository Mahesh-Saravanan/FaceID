{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\miniconda3\\envs\\facerec\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_entry (vectorDB,mtcnn,resnet,device): \n",
    "    id_ = input(\"Enter your ID\")\n",
    "\n",
    "    a = {id_: {\n",
    "                \"id_vectors\": []\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    print(\"Recording...\") \n",
    "    a[id_][\"id_vectors\"] =  get_vector(mtcnn,resnet,device)\n",
    "    print(f\"Samples---{len(a[id_][\"id_vectors\"] )} running on {device}\")\n",
    "    vectorDB.update(a)\n",
    "\n",
    "\n",
    "def get_vector(mtcnn,resnet,device):\n",
    "    vectors = []\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "   \n",
    "    n_samples = 50\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "\n",
    "        \n",
    "        percentage = (len(vectors)/n_samples)*100\n",
    "        \n",
    "        \n",
    "        cv2.putText(frame, f\"Recording: {int(percentage)}%\", (10, frame.shape[0] - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame_rgb)\n",
    "\n",
    "    \n",
    "        face_tensor = mtcnn(img)\n",
    "\n",
    "        \n",
    "        boxes, _ = mtcnn.detect(img)\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                box = [int(b) for b in box]\n",
    "                cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "\n",
    "        \n",
    "        if face_tensor is not None:\n",
    "            face_tensor = face_tensor.unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                embedding = resnet(face_tensor)\n",
    "            \n",
    "            embedding_np = embedding.cpu().numpy().flatten()\n",
    "            cv2.putText(frame, f\"Recording data...\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            vectors.append(embedding_np)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        \n",
    "        cv2.imshow('Live Face Authentication', frame)\n",
    "        \n",
    "        \n",
    "        if percentage >= 98 or cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return torch.tensor(np.array(vectors))\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorDB = dict()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(image_size=160, margin=20, device=device)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Samples---50 running on cuda\n"
     ]
    }
   ],
   "source": [
    "make_entry (vectorDB,mtcnn,resnet,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1', '2', '3'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorDB.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to grab frame\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(frame_rgb)\n",
    "    face_tensor = mtcnn(img)\n",
    "    if face_tensor is not None:\n",
    "        face_tensor = face_tensor.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = resnet(face_tensor)\n",
    "        \n",
    "        embedding_np = embedding.cpu().numpy().flatten()\n",
    "    if  cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_cosine(source_vec, target_vec):\n",
    "    cosine_sim = F.cosine_similarity(source_vec, target_vec, dim=1)\n",
    "    return torch.mean(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181321024894714"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_cosine(source_vec, target_vec).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.07336177676916122\n",
      "1 0.018844662234187126\n",
      "1 0.05815839767456055\n",
      "1 0.0872763991355896\n",
      "1 0.09036781638860703\n",
      "1 0.11031754314899445\n",
      "1 0.10677248239517212\n",
      "1 0.03559480234980583\n",
      "1 0.09543789178133011\n",
      "1 0.11109425872564316\n",
      "1 0.10678990185260773\n",
      "1 0.13766157627105713\n",
      "3 0.588904619216919\n",
      "3 0.5905807614326477\n",
      "1 0.31200283765792847\n",
      "1 0.40272057056427\n",
      "1 0.12003380060195923\n",
      "1 0.13414879143238068\n",
      "1 0.18388324975967407\n",
      "1 0.20881590247154236\n",
      "1 0.17436911165714264\n",
      "1 0.15250298380851746\n",
      "1 0.1960173398256302\n",
      "1 0.3311907947063446\n",
      "1 0.23497070372104645\n",
      "1 0.2868334949016571\n",
      "1 0.13887324929237366\n",
      "1 0.09863264113664627\n",
      "1 0.1416199505329132\n",
      "1 0.10928623378276825\n",
      "1 0.08442482352256775\n",
      "1 0.1071598157286644\n",
      "1 0.09740563482046127\n",
      "1 0.12177770584821701\n",
      "1 0.07537279278039932\n",
      "1 0.14314430952072144\n",
      "1 0.1415897011756897\n",
      "1 0.08397383987903595\n",
      "1 0.12647698819637299\n",
      "1 0.11023363471031189\n",
      "1 0.09782392531633377\n",
      "1 0.36540713906288147\n",
      "1 0.46421128511428833\n",
      "1 0.14764265716075897\n",
      "1 0.25197529792785645\n",
      "1 0.22120679914951324\n",
      "3 0.5876116156578064\n",
      "3 0.6050581336021423\n",
      "1 0.17331461608409882\n",
      "1 0.13696949183940887\n",
      "1 0.26315775513648987\n",
      "1 0.3974319398403168\n",
      "1 0.13831159472465515\n",
      "1 0.5030418634414673\n",
      "1 0.552176833152771\n",
      "1 0.16912440955638885\n",
      "1 0.1505686640739441\n",
      "1 0.14103646576404572\n",
      "1 0.20837034285068512\n",
      "1 0.33439892530441284\n",
      "1 0.10282760858535767\n",
      "1 0.0933087095618248\n",
      "1 0.1430339217185974\n",
      "1 0.14144840836524963\n",
      "1 0.21582792699337006\n",
      "1 0.21701093018054962\n",
      "1 0.5317676067352295\n",
      "1 0.11826673150062561\n",
      "1 0.076517753303051\n",
      "1 0.118006631731987\n",
      "1 0.1556912064552307\n",
      "1 0.17499153316020966\n",
      "1 0.1954837441444397\n",
      "1 0.1965310424566269\n",
      "1 0.12180712819099426\n",
      "1 0.11817881464958191\n",
      "1 0.14667333662509918\n",
      "2 0.5125024914741516\n",
      "1 0.1984156221151352\n",
      "3 0.5719676613807678\n",
      "3 0.6408726572990417\n",
      "1 0.3250088393688202\n",
      "1 0.3047352731227875\n",
      "2 0.673824667930603\n",
      "2 0.5621820688247681\n",
      "2 0.7357099652290344\n",
      "1 0.4311922490596771\n",
      "1 0.3830311596393585\n",
      "1 0.19369104504585266\n",
      "1 0.3720591366291046\n",
      "2 0.6217730045318604\n",
      "2 0.6421693563461304\n",
      "3 0.7371107339859009\n",
      "1 0.4085240066051483\n",
      "3 0.19234201312065125\n",
      "3 0.5637568831443787\n",
      "2 0.7308382987976074\n",
      "2 0.6304712891578674\n",
      "2 0.6631947159767151\n",
      "2 0.6372392773628235\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(frame_rgb)\n",
    "    face_tensor = mtcnn(img)\n",
    "    if face_tensor is not None:\n",
    "        face_tensor = face_tensor.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = resnet(face_tensor)\n",
    "        \n",
    "        embedding_np = embedding.cpu().detach().flatten()\n",
    "        id_,val = search_DB(embedding_np)\n",
    "        print(id_,val)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"Webcam Feed\", frame)\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_DB(ref = None):\n",
    "    matched = dict()\n",
    "    for k in vectorDB.keys():\n",
    "        target = vectorDB[k][\"id_vectors\"]\n",
    "        sim = cal_cosine(ref, target).item()\n",
    "        matched.update({k:sim})\n",
    "    id_ = max(matched, key=matched.get)\n",
    "    val = matched[k]\n",
    "\n",
    "    return id_,val\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facerec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
